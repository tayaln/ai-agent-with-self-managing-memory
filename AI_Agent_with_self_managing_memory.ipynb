{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f896bca1-3800-43ab-ac32-3ed5ee7133ec",
      "metadata": {
        "id": "f896bca1-3800-43ab-ac32-3ed5ee7133ec"
      },
      "source": [
        "# Lab 1: Implementing self-editing memory from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vJLmmMcf7HLK"
      },
      "id": "vJLmmMcf7HLK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hi, My boyfriend's name is Virat\n",
        "\n",
        "A - Hi\n",
        "\n",
        "Write a poem on my boyfried's name\n",
        "\n",
        "My boy fried's name is Sachin"
      ],
      "metadata": {
        "id": "begUZxjVRlld"
      },
      "id": "begUZxjVRlld"
    },
    {
      "cell_type": "markdown",
      "source": [
        "AI Agents -> tools\n",
        "\n",
        "Tool -> Managing / editing the memory"
      ],
      "metadata": {
        "id": "91KAmHgvSI3M"
      },
      "id": "91KAmHgvSI3M"
    },
    {
      "cell_type": "markdown",
      "id": "1480aa66-5437-4454-a6ad-dbece7146277",
      "metadata": {
        "id": "1480aa66-5437-4454-a6ad-dbece7146277"
      },
      "source": [
        "## Section 0: Setup OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python_dotenv==1.0.1 openai==1.45.1 letta==0.1.4 crewai-tools==0.12.0\n"
      ],
      "metadata": {
        "id": "C-osPRsWPi6q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f8e4f6a-c3d7-4b83-a621-a3150434ba13"
      },
      "id": "C-osPRsWPi6q",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python_dotenv==1.0.1\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting openai==1.45.1\n",
            "  Downloading openai-1.45.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting letta==0.1.4\n",
            "  Downloading letta-0.1.4-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting crewai-tools==0.12.0\n",
            "  Downloading crewai_tools-0.12.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.45.1) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.45.1) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.45.1) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.45.1) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.45.1) (2.10.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.45.1) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai==1.45.1) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai==1.45.1) (4.12.2)\n",
            "Collecting chromadb<0.5.0,>=0.4.24 (from letta==0.1.4)\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting demjson3<4.0.0,>=3.0.6 (from letta==0.1.4)\n",
            "  Downloading demjson3-3.0.6.tar.gz (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: docstring-parser<0.17,>=0.16 in /usr/local/lib/python3.11/dist-packages (from letta==0.1.4) (0.16)\n",
            "Collecting docx2txt<0.9,>=0.8 (from letta==0.1.4)\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting html2text<2021.0.0,>=2020.1.16 (from letta==0.1.4)\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.45.1)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from letta==0.1.4)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from letta==0.1.4) (3.1.5)\n",
            "Collecting llama-index<0.12.0,>=0.11.9 (from letta==0.1.4)\n",
            "  Downloading llama_index-0.11.23-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.5 (from letta==0.1.4)\n",
            "  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\n",
            "Collecting locust<3.0.0,>=2.31.5 (from letta==0.1.4)\n",
            "  Downloading locust-2.32.6-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from letta==0.1.4) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from letta==0.1.4) (1.26.4)\n",
            "Requirement already satisfied: prettytable<4.0.0,>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from letta==0.1.4) (3.12.0)\n",
            "Collecting pydantic-settings<3.0.0,>=2.2.1 (from letta==0.1.4)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: python-box<8.0.0,>=7.1.1 in /usr/local/lib/python3.11/dist-packages (from letta==0.1.4) (7.3.0)\n",
            "Collecting python-multipart<0.0.10,>=0.0.9 (from letta==0.1.4)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pytz<2024.0,>=2023.3.post1 (from letta==0.1.4)\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from letta==0.1.4) (6.0.2)\n",
            "Collecting questionary<3.0.0,>=2.0.1 (from letta==0.1.4)\n",
            "  Downloading questionary-2.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting setuptools<69.0.0,>=68.2.2 (from letta==0.1.4)\n",
            "  Downloading setuptools-68.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.25 in /usr/local/lib/python3.11/dist-packages (from letta==0.1.4) (2.0.37)\n",
            "Collecting sqlalchemy-json<0.8.0,>=0.7.0 (from letta==0.1.4)\n",
            "  Downloading sqlalchemy_json-0.7.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting sqlalchemy-utils<0.42.0,>=0.41.2 (from letta==0.1.4)\n",
            "  Downloading SQLAlchemy_Utils-0.41.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting sqlmodel<0.0.17,>=0.0.16 (from letta==0.1.4)\n",
            "  Downloading sqlmodel-0.0.16-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting tiktoken<0.8.0,>=0.7.0 (from letta==0.1.4)\n",
            "  Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting typer<0.10.0,>=0.9.0 (from typer[all]<0.10.0,>=0.9.0->letta==0.1.4)\n",
            "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from crewai-tools==0.12.0) (4.12.3)\n",
            "Collecting docker<8.0.0,>=7.1.0 (from crewai-tools==0.12.0)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting embedchain<0.2.0,>=0.1.114 (from crewai-tools==0.12.0)\n",
            "  Downloading embedchain-0.1.126-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting lancedb<0.6.0,>=0.5.4 (from crewai-tools==0.12.0)\n",
            "  Downloading lancedb-0.5.7-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting langchain<=0.3,>0.2 (from crewai-tools==0.12.0)\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting pyright<2.0.0,>=1.1.350 (from crewai-tools==0.12.0)\n",
            "  Downloading pyright-1.1.392.post0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: pytest<9.0.0,>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools==0.12.0) (8.3.4)\n",
            "Collecting pytube<16.0.0,>=15.0.0 (from crewai-tools==0.12.0)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from crewai-tools==0.12.0) (2.32.3)\n",
            "Collecting selenium<5.0.0,>=4.18.1 (from crewai-tools==0.12.0)\n",
            "  Downloading selenium-4.27.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai==1.45.1) (3.10)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->crewai-tools==0.12.0) (2.6)\n",
            "Collecting build>=1.0.3 (from chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading posthog-3.8.3-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading pulsar_client-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.24->letta==0.1.4) (1.29.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.24->letta==0.1.4) (1.29.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.24->letta==0.1.4) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.24->letta==0.1.4) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.24->letta==0.1.4) (1.69.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.24->letta==0.1.4) (9.0.0)\n",
            "Collecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading mmh3-5.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb<0.5.0,>=0.4.24->letta==0.1.4) (3.10.14)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8.0.0,>=7.1.0->crewai-tools==0.12.0) (2.3.0)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "INFO: pip is looking at multiple versions of embedchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting embedchain<0.2.0,>=0.1.114 (from crewai-tools==0.12.0)\n",
            "  Downloading embedchain-0.1.125-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.124-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting cohere<6.0,>=5.3 (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading cohere-5.13.8-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (1.74.0)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting embedchain<0.2.0,>=0.1.114 (from crewai-tools==0.12.0)\n",
            "  Downloading embedchain-0.1.123-py3-none-any.whl.metadata (9.3 kB)\n",
            "  Downloading embedchain-0.1.122-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading langchain_cohere-0.1.9-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting langchain-community<0.3.0,>=0.2.6 (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading langchain_community-0.2.19-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-openai<0.2.0,>=0.1.7 (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting mem0ai<0.2.0,>=0.1.15 (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading mem0ai-0.1.45-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.7.0 in /usr/local/lib/python3.11/dist-packages (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (13.9.4)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.45.1) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.45.1) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.45.1) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.4->letta==0.1.4) (3.0.2)\n",
            "Collecting deprecation (from lancedb<0.6.0,>=0.5.4->crewai-tools==0.12.0)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pylance==0.9.18 (from lancedb<0.6.0,>=0.5.4->crewai-tools==0.12.0)\n",
            "  Downloading pylance-0.9.18-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting ratelimiter~=1.0 (from lancedb<0.6.0,>=0.5.4->crewai-tools==0.12.0)\n",
            "  Downloading ratelimiter-1.2.0.post0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting retry>=0.9.2 (from lancedb<0.6.0,>=0.5.4->crewai-tools==0.12.0)\n",
            "  Downloading retry-0.9.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.11/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai-tools==0.12.0) (24.3.0)\n",
            "Collecting semver>=3.0 (from lancedb<0.6.0,>=0.5.4->crewai-tools==0.12.0)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai-tools==0.12.0) (5.5.0)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from lancedb<0.6.0,>=0.5.4->crewai-tools==0.12.0) (8.1.8)\n",
            "Requirement already satisfied: pyarrow>=12 in /usr/local/lib/python3.11/dist-packages (from pylance==0.9.18->lancedb<0.6.0,>=0.5.4->crewai-tools==0.12.0) (17.0.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain<=0.3,>0.2->crewai-tools==0.12.0) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain<=0.3,>0.2->crewai-tools==0.12.0) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain<=0.3,>0.2->crewai-tools==0.12.0) (0.3.5)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain<=0.3,>0.2->crewai-tools==0.12.0)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting tenacity>=8.2.3 (from chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting llama-index-agent-openai<0.4.0,>=0.3.4 (from llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-cli<0.4.0,>=0.3.1 (from llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.12.0,>=0.11.23 (from llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_index_core-0.11.23-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.3.0,>=0.2.10 (from llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.2.3-py3-none-any.whl.metadata (729 bytes)\n",
            "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.4.0,>=0.3.0 (from llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_index_readers_file-0.3.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting ConfigArgParse>=1.5.5 (from locust<3.0.0,>=2.31.5->letta==0.1.4)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting Flask-Cors>=3.0.10 (from locust<3.0.0,>=2.31.5->letta==0.1.4)\n",
            "  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting Flask-Login>=0.6.3 (from locust<3.0.0,>=2.31.5->letta==0.1.4)\n",
            "  Downloading Flask_Login-0.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: Werkzeug>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3.0.0,>=2.31.5->letta==0.1.4) (3.1.3)\n",
            "Requirement already satisfied: flask>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3.0.0,>=2.31.5->letta==0.1.4) (3.1.0)\n",
            "Collecting gevent>=22.10.2 (from locust<3.0.0,>=2.31.5->letta==0.1.4)\n",
            "  Downloading gevent-24.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting geventhttpclient>=2.3.1 (from locust<3.0.0,>=2.31.5->letta==0.1.4)\n",
            "  Downloading geventhttpclient-2.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3.0.0,>=2.31.5->letta==0.1.4) (1.1.0)\n",
            "Requirement already satisfied: psutil>=5.9.1 in /usr/local/lib/python3.11/dist-packages (from locust<3.0.0,>=2.31.5->letta==0.1.4) (5.9.5)\n",
            "Collecting pyzmq>=25.0.0 (from locust<3.0.0,>=2.31.5->letta==0.1.4)\n",
            "  Downloading pyzmq-26.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.2 kB)\n",
            "INFO: pip is looking at multiple versions of locust to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting locust<3.0.0,>=2.31.5 (from letta==0.1.4)\n",
            "  Downloading locust-2.32.5-py3-none-any.whl.metadata (10.0 kB)\n",
            "  Downloading locust-2.32.4-py3-none-any.whl.metadata (10.0 kB)\n",
            "  Downloading locust-2.32.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->letta==0.1.4) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<4.0.0,>=3.8.1->letta==0.1.4) (2024.11.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable<4.0.0,>=3.9.0->letta==0.1.4) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.45.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.45.1) (2.27.2)\n",
            "Collecting nodeenv>=1.6.0 (from pyright<2.0.0,>=1.1.350->crewai-tools==0.12.0)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<9.0.0,>=8.0.0->crewai-tools==0.12.0) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytest<9.0.0,>=8.0.0->crewai-tools==0.12.0) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest<9.0.0,>=8.0.0->crewai-tools==0.12.0) (1.5.0)\n",
            "Requirement already satisfied: prompt_toolkit<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from questionary<3.0.0,>=2.0.1->letta==0.1.4) (3.0.48)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->crewai-tools==0.12.0) (3.4.1)\n",
            "Collecting trio~=0.17 (from selenium<5.0.0,>=4.18.1->crewai-tools==0.12.0)\n",
            "  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.18.1->crewai-tools==0.12.0)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium<5.0.0,>=4.18.1->crewai-tools==0.12.0) (1.8.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3.0.0,>=2.0.25->letta==0.1.4) (3.1.1)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<0.10.0,>=0.9.0->letta==0.1.4)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer[all]<0.10.0,>=0.9.0->letta==0.1.4) (1.5.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.3,>0.2->crewai-tools==0.12.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.3,>0.2->crewai-tools==0.12.0) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.3,>0.2->crewai-tools==0.12.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.3,>0.2->crewai-tools==0.12.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.3,>0.2->crewai-tools==0.12.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.3,>0.2->crewai-tools==0.12.0) (1.18.3)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->locust<3.0.0,>=2.31.5->letta==0.1.4) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->locust<3.0.0,>=2.31.5->letta==0.1.4) (1.9.0)\n",
            "Collecting zope.event (from gevent>=22.10.2->locust<3.0.0,>=2.31.5->letta==0.1.4)\n",
            "  Downloading zope.event-5.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting zope.interface (from gevent>=22.10.2->locust<3.0.0,>=2.31.5->letta==0.1.4)\n",
            "  Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from geventhttpclient>=2.3.1->locust<3.0.0,>=2.31.5->letta==0.1.4)\n",
            "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (4.25.5)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (1.14.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (2.0.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->letta==0.1.4) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->letta==0.1.4) (2.8.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->letta==0.1.4) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->letta==0.1.4) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "INFO: pip is looking at multiple versions of langchain-cohere to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-cohere<0.2.0,>=0.1.4 (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading langchain_cohere-0.1.8-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading langchain_cohere-0.1.7-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading langchain_cohere-0.1.5-py3-none-any.whl.metadata (6.4 kB)\n",
            "  Downloading langchain_cohere-0.1.4-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting langchain<=0.3,>0.2 (from crewai-tools==0.12.0)\n",
            "  Downloading langchain-0.2.17-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.43 (from langchain<=0.3,>0.2->crewai-tools==0.12.0)\n",
            "  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<=0.3,>0.2->crewai-tools==0.12.0)\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-experimental>=0.0.6 (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pandas>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (2.2.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.43->langchain<=0.3,>0.2->crewai-tools==0.12.0) (1.33)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.3.0,>=0.2.6->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<=0.3,>0.2->crewai-tools==0.12.0) (1.0.0)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index<0.12.0,>=0.11.9->letta==0.1.4) (1.2.15)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.23->llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.12.0,>=0.11.23->llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index<0.12.0,>=0.11.9->letta==0.1.4) (2024.10.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index<0.12.0,>=0.11.9->letta==0.1.4) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index<0.12.0,>=0.11.9->letta==0.1.4) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index<0.12.0,>=0.11.9->letta==0.1.4) (11.1.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.12.0,>=0.11.23->llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.12.0,>=0.11.23->llama-index<0.12.0,>=0.11.9->letta==0.1.4) (1.17.0)\n",
            "Collecting llama-cloud>=0.1.5 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_cloud-0.1.9-py3-none-any.whl.metadata (911 bytes)\n",
            "INFO: pip is looking at multiple versions of llama-index-indices-managed-llama-cloud to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is looking at multiple versions of llama-index-readers-file to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index<0.12.0,>=0.11.9 (from letta==0.1.4)\n",
            "  Downloading llama_index-0.11.22-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "INFO: pip is still looking at multiple versions of locust to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of llama-index-readers-llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading llama_parse-0.5.19-py3-none-any.whl.metadata (7.0 kB)\n",
            "INFO: pip is looking at multiple versions of mem0ai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mem0ai<0.2.0,>=0.1.15 (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading mem0ai-0.1.44-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.43-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.42-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.41-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.40-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.39-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.38-py3-none-any.whl.metadata (10 kB)\n",
            "INFO: pip is still looking at multiple versions of mem0ai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading mem0ai-0.1.37-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.36-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.35-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.34-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.33-py3-none-any.whl.metadata (10 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading mem0ai-0.1.32-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.31-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.30-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.29-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.28-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.27-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.26-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.25-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.24-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.23-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.22-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.21-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.20-py3-none-any.whl.metadata (10 kB)\n",
            "  Downloading mem0ai-0.1.19-py3-none-any.whl.metadata (9.9 kB)\n",
            "  Downloading mem0ai-0.1.18-py3-none-any.whl.metadata (9.9 kB)\n",
            "  Downloading mem0ai-0.1.17-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting neo4j<6.0.0,>=5.23.1 (from mem0ai<0.2.0,>=0.1.15->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading neo4j-5.27.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting mem0ai<0.2.0,>=0.1.15 (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading mem0ai-0.1.16-py3-none-any.whl.metadata (10.0 kB)\n",
            "  Downloading mem0ai-0.1.15-py3-none-any.whl.metadata (9.9 kB)\n",
            "INFO: pip is still looking at multiple versions of embedchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting embedchain<0.2.0,>=0.1.114 (from crewai-tools==0.12.0)\n",
            "  Downloading embedchain-0.1.121-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting mem0ai<0.0.21,>=0.0.20 (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading mem0ai-0.0.20-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting embedchain<0.2.0,>=0.1.114 (from crewai-tools==0.12.0)\n",
            "  Downloading embedchain-0.1.120-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting mem0ai<0.0.10,>=0.0.9 (from embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading mem0ai-0.0.9-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting qdrant-client<2.0.0,>=1.9.1 (from mem0ai<0.0.10,>=0.0.9->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading qdrant_client-1.13.0-py3-none-any.whl.metadata (10 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-cohere to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: pip is still looking at multiple versions of llama-index-indices-managed-llama-cloud to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->letta==0.1.4) (24.12.23)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->letta==0.1.4) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.24->letta==0.1.4) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.24->letta==0.1.4) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->letta==0.1.4) (0.50b0)\n",
            "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.11/dist-packages (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai-tools==0.12.0) (4.4.2)\n",
            "Collecting py<2.0.0,>=1.4.26 (from retry>=0.9.2->lancedb<0.6.0,>=0.5.4->crewai-tools==0.12.0)\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.24->letta==0.1.4) (0.27.1)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai-tools==0.12.0)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.18.1->crewai-tools==0.12.0)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.18.1->crewai-tools==0.12.0)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.18.1->crewai-tools==0.12.0) (1.7.1)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->letta==0.1.4) (14.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3.0,>=0.2.6->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading marshmallow-3.25.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (1.62.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (0.14.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (1.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.5.0,>=0.4.24->letta==0.1.4) (3.16.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.24->letta==0.1.4) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.43->langchain<=0.3,>0.2->crewai-tools==0.12.0) (3.0.0)\n",
            "INFO: pip is looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-experimental>=0.0.6 (from langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading langchain_experimental-0.3.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading langchain_experimental-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading langchain_experimental-0.3.1.post1-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading langchain_experimental-0.3.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading langchain_experimental-0.3.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading langchain_experimental-0.0.65-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.7.0->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (0.1.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4.3->langchain-cohere<0.2.0,>=0.1.4->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (2024.2)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.10,>=0.0.9->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading grpcio_tools-1.69.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.10,>=0.0.9->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.23->llama-index<0.12.0,>=0.11.9->letta==0.1.4)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->letta==0.1.4)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->letta==0.1.4) (1.3.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.10,>=0.0.9->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0) (0.6.1)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.10,>=0.0.9->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.0.10,>=0.0.9->embedchain<0.2.0,>=0.1.114->crewai-tools==0.12.0)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading openai-1.45.1-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.2/374.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading letta-0.1.4-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crewai_tools-0.12.0-py3-none-any.whl (463 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.3/463.3 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2023.4-py2.py3-none-any.whl (506 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading embedchain-0.1.120-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.9/210.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mem0ai-0.0.9-py3-none-any.whl (29 kB)\n",
            "Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading lancedb-0.5.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylance-0.9.18-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.2.17-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_cohere-0.1.9-py3-none-any.whl (35 kB)\n",
            "Downloading langchain_core-0.2.43-py3-none-any.whl (397 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.1/397.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index-0.11.22-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading locust-2.32.3-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading pyright-1.1.392.post0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading questionary-2.1.0-py3-none-any.whl (36 kB)\n",
            "Downloading selenium-4.27.1-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-68.2.2-py3-none-any.whl (807 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sqlalchemy_json-0.7.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading SQLAlchemy_Utils-0.41.2-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sqlmodel-0.0.16-py3-none-any.whl (26 kB)\n",
            "Downloading tiktoken-0.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading cohere-5.13.8-py3-none-any.whl (251 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Downloading Flask_Login-0.6.3-py3-none-any.whl (17 kB)\n",
            "Downloading gevent-24.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading geventhttpclient-2.3.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.0/113.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.2.19-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.1.25-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_core-0.11.23-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_indices_managed_llama_cloud-0.6.0-py3-none-any.whl (11 kB)\n",
            "Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.2.16-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.2.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading mmh3-5.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.8.3-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pulsar_client-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzmq-26.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.2/869.2 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ratelimiter-1.2.0.post0-py3-none-any.whl (6.6 kB)\n",
            "Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
            "Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.3/486.3 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.0.65-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_cloud-0.1.9-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.0/241.0 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.5.19-py3-none-any.whl (15 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qdrant_client-1.13.0-py3-none-any.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.4/306.4 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading zope.event-5.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.8/259.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading grpcio_tools-1.69.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.25.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: demjson3, docx2txt, pypika\n",
            "  Building wheel for demjson3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for demjson3: filename=demjson3-3.0.6-py3-none-any.whl size=75281 sha256=9d8bc566f80b5c521771ee53dca6d3f89344fa2de2ced6937727146bfe663692\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/9d/d5/e8cbb4d529989f6d3f347fe914559ea4f66715bf299763af1c\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=292660edf1b8a76e7813ed9e106b042cba1d928af6b226a3a2d757e2108fcf62\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0e/7a/3094a4ceefe657bff7e12dd9592a9d5b6487ef4338ace0afa6\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53771 sha256=ab330f51564351cf348014d1b3215ad5fdad7c7365f295e8e3df60ddec2f10c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built demjson3 docx2txt pypika\n",
            "Installing collected packages: striprtf, sortedcontainers, schema, ratelimiter, pytz, pypika, monotonic, filetype, durationpy, docx2txt, dirtyjson, demjson3, brotli, wsproto, uvloop, uvicorn, types-requests, typer, tenacity, setuptools, semver, pyzmq, pytube, python-multipart, python_dotenv, pysbd, pyproject_hooks, pypdf, py, pulsar-client, protobuf, portalocker, parameterized, overrides, outcome, opentelemetry-util-http, nodeenv, mypy-extensions, mmh3, marshmallow, Mako, hyperframe, humanfriendly, httpx-sse, httptools, html2text, hpack, fastavro, deprecation, ConfigArgParse, colorama, chroma-hnswlib, bcrypt, backoff, asgiref, zope.interface, zope.event, watchfiles, typing-inspect, trio, tiktoken, starlette, sqlalchemy-utils, sqlalchemy-json, retry, questionary, pyright, pylance, posthog, opentelemetry-proto, httpx, h2, grpcio-tools, gptcache, docker, coloredlogs, build, alembic, trio-websocket, sqlmodel, pydantic-settings, opentelemetry-exporter-otlp-proto-common, openai, onnxruntime, llama-cloud, langsmith, lancedb, kubernetes, gevent, Flask-Login, Flask-Cors, fastapi, dataclasses-json, selenium, qdrant-client, opentelemetry-instrumentation, llama-index-legacy, llama-index-core, langchain-core, geventhttpclient, cohere, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, mem0ai, locust, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, langchain-text-splitters, langchain-openai, opentelemetry-instrumentation-fastapi, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, langchain, llama-index-program-openai, langchain-community, chromadb, llama-index-question-gen-openai, langchain-experimental, llama-index, langchain-cohere, letta, embedchain, crewai-tools\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2024.2\n",
            "    Uninstalling pytz-2024.2:\n",
            "      Successfully uninstalled pytz-2024.2\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.15.1\n",
            "    Uninstalling typer-0.15.1:\n",
            "      Successfully uninstalled typer-0.15.1\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.1.0\n",
            "    Uninstalling setuptools-75.1.0:\n",
            "      Successfully uninstalled setuptools-75.1.0\n",
            "  Attempting uninstall: pyzmq\n",
            "    Found existing installation: pyzmq 24.0.1\n",
            "    Uninstalling pyzmq-24.0.1:\n",
            "      Successfully uninstalled pyzmq-24.0.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.59.6\n",
            "    Uninstalling openai-1.59.6:\n",
            "      Successfully uninstalled openai-1.59.6\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.2.10\n",
            "    Uninstalling langsmith-0.2.10:\n",
            "      Successfully uninstalled langsmith-0.2.10\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.29\n",
            "    Uninstalling langchain-core-0.3.29:\n",
            "      Successfully uninstalled langchain-core-0.3.29\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.5\n",
            "    Uninstalling langchain-text-splitters-0.3.5:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.5\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.14\n",
            "    Uninstalling langchain-0.3.14:\n",
            "      Successfully uninstalled langchain-0.3.14\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "notebook 6.5.5 requires pyzmq<25,>=17, but you have pyzmq 26.2.0 which is incompatible.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ConfigArgParse-1.7 Flask-Cors-5.0.0 Flask-Login-0.6.3 Mako-1.3.8 alembic-1.14.1 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 brotli-1.1.0 build-1.2.2.post1 chroma-hnswlib-0.7.3 chromadb-0.4.24 cohere-5.13.8 colorama-0.4.6 coloredlogs-15.0.1 crewai-tools-0.12.0 dataclasses-json-0.6.7 demjson3-3.0.6 deprecation-2.1.0 dirtyjson-1.0.8 docker-7.1.0 docx2txt-0.8 durationpy-0.9 embedchain-0.1.120 fastapi-0.115.6 fastavro-1.10.0 filetype-1.2.0 gevent-24.11.1 geventhttpclient-2.3.3 gptcache-0.1.44 grpcio-tools-1.69.0 h2-4.1.0 hpack-4.0.0 html2text-2020.1.16 httptools-0.6.4 httpx-0.27.2 httpx-sse-0.4.0 humanfriendly-10.0 hyperframe-6.0.1 kubernetes-31.0.0 lancedb-0.5.7 langchain-0.2.17 langchain-cohere-0.1.9 langchain-community-0.2.19 langchain-core-0.2.43 langchain-experimental-0.0.65 langchain-openai-0.1.25 langchain-text-splitters-0.2.4 langsmith-0.1.147 letta-0.1.4 llama-cloud-0.1.9 llama-index-0.11.22 llama-index-agent-openai-0.3.4 llama-index-cli-0.3.1 llama-index-core-0.11.23 llama-index-embeddings-openai-0.2.5 llama-index-indices-managed-llama-cloud-0.6.0 llama-index-legacy-0.9.48.post4 llama-index-llms-openai-0.2.16 llama-index-multi-modal-llms-openai-0.2.3 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.2 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.19 locust-2.32.3 marshmallow-3.25.1 mem0ai-0.0.9 mmh3-5.0.1 monotonic-1.6 mypy-extensions-1.0.0 nodeenv-1.9.1 onnxruntime-1.20.1 openai-1.45.1 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-instrumentation-0.50b0 opentelemetry-instrumentation-asgi-0.50b0 opentelemetry-instrumentation-fastapi-0.50b0 opentelemetry-proto-1.29.0 opentelemetry-util-http-0.50b0 outcome-1.3.0.post0 overrides-7.7.0 parameterized-0.9.0 portalocker-2.10.1 posthog-3.8.3 protobuf-5.29.3 pulsar-client-3.5.0 py-1.11.0 pydantic-settings-2.7.1 pylance-0.9.18 pypdf-4.3.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyright-1.1.392.post0 pysbd-0.3.4 python-multipart-0.0.9 python_dotenv-1.0.1 pytube-15.0.0 pytz-2023.4 pyzmq-26.2.0 qdrant-client-1.13.0 questionary-2.1.0 ratelimiter-1.2.0.post0 retry-0.9.2 schema-0.7.7 selenium-4.27.1 semver-3.0.2 setuptools-68.2.2 sortedcontainers-2.4.0 sqlalchemy-json-0.7.0 sqlalchemy-utils-0.41.2 sqlmodel-0.0.16 starlette-0.41.3 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.7.0 trio-0.28.0 trio-websocket-0.11.1 typer-0.9.4 types-requests-2.32.0.20241016 typing-inspect-0.9.0 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4 wsproto-1.2.0 zope.event-5.0 zope.interface-7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "setuptools"
                ]
              },
              "id": "66a43cb3a6a243b7a77db9c99782910f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PYFGdvTeHU1M"
      },
      "id": "PYFGdvTeHU1M"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c5e108e4-bcf9-4be1-b2c0-66539cbe9ec3",
      "metadata": {
        "height": 47,
        "id": "c5e108e4-bcf9-4be1-b2c0-66539cbe9ec3"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('OPEN_API_KEY')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7a0e6729-0f02-497f-8f85-688ed4f65f68",
      "metadata": {
        "height": 115,
        "id": "7a0e6729-0f02-497f-8f85-688ed4f65f68"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=openai_api_key\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c84fe7e5-fc76-427b-a21b-37515ef05e2b",
      "metadata": {
        "id": "c84fe7e5-fc76-427b-a21b-37515ef05e2b"
      },
      "source": [
        "## Section 1: Breaking down the LLM context window\n",
        "### A simple agent's context window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "16bbb19b-2fa2-4cac-8803-5cb179c36d47",
      "metadata": {
        "height": 30,
        "id": "16bbb19b-2fa2-4cac-8803-5cb179c36d47"
      },
      "outputs": [],
      "source": [
        "model = \"gpt-4o-mini\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1ed0f467-c545-4b26-8a10-2cb009240b5a",
      "metadata": {
        "height": 30,
        "id": "1ed0f467-c545-4b26-8a10-2cb009240b5a"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"You are a helpful chatbot.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "75cc6a09-6c24-4b45-8b92-6084acdc3d46",
      "metadata": {
        "height": 200,
        "id": "75cc6a09-6c24-4b45-8b92-6084acdc3d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c4b1db59-d2ed-4f1f-cbae-239c281963de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, but I don't know your name. You can tell me if you'd like!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Make the completion request with the tool usage\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "        # system prompt: always included in the context window\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        # chat history (evolves over time)\n",
        "        {\"role\": \"user\", \"content\": \"What is my name?\"},\n",
        "    ]\n",
        ")\n",
        "chat_completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f33edc1-58e9-4e04-a338-3ec3c2553812",
      "metadata": {
        "id": "4f33edc1-58e9-4e04-a338-3ec3c2553812"
      },
      "source": [
        "### Adding memory to the context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1d2cc3dd-0278-40f7-8c0e-e919cb628c31",
      "metadata": {
        "height": 81,
        "id": "1d2cc3dd-0278-40f7-8c0e-e919cb628c31"
      },
      "outputs": [],
      "source": [
        "agent_memory = {\"human\": \"Name: Sachin\"}\n",
        "system_prompt = \"You are a helpful chatbot. \" \\\n",
        "+ \"You have a section of your context called [MEMORY] \" \\\n",
        "+ \"that contains information relevant to your conversation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bf728dce-f06b-4bcb-a3ba-15a7f099b2d9",
      "metadata": {
        "height": 251,
        "id": "bf728dce-f06b-4bcb-a3ba-15a7f099b2d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0257d9b9-3851-4210-d3b4-acd0fe4ae87d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your name is Sachin.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "        # system prompt\n",
        "        {\"role\": \"system\", \"content\": system_prompt + \"[MEMORY]\\n\" + \\\n",
        "         json.dumps(agent_memory)},\n",
        "        # chat history\n",
        "        {\"role\": \"user\", \"content\": \"What is my name?\"},\n",
        "    ],\n",
        ")\n",
        "chat_completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "623e462b-7610-413b-a0da-26a2375028a8",
      "metadata": {
        "id": "623e462b-7610-413b-a0da-26a2375028a8"
      },
      "source": [
        "## Section 2: Modifing the memory with tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04ac86ab-03ec-4656-9bb8-62016edc7b5a",
      "metadata": {
        "id": "04ac86ab-03ec-4656-9bb8-62016edc7b5a"
      },
      "source": [
        "### Defining a memory editing tool\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "76d419bd-020c-4f6f-81c3-e704d65f5306",
      "metadata": {
        "height": 98,
        "id": "76d419bd-020c-4f6f-81c3-e704d65f5306"
      },
      "outputs": [],
      "source": [
        "agent_memory = {\"human\": \"\", \"agent\": \"\"}\n",
        "\n",
        "def core_memory_save(section: str, memory: str):\n",
        "    agent_memory[section] += '\\n'\n",
        "    agent_memory[section] += memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2df27d7b-d2b6-4d87-90c3-6759a70fa8d7",
      "metadata": {
        "height": 30,
        "id": "2df27d7b-d2b6-4d87-90c3-6759a70fa8d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f5a5f0e-4469-41d3-a87a-46d173b5afe2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'human': '', 'agent': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "agent_memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "571e53e5-4190-4787-9cb2-efc527885c2d",
      "metadata": {
        "height": 30,
        "id": "571e53e5-4190-4787-9cb2-efc527885c2d"
      },
      "outputs": [],
      "source": [
        "core_memory_save(\"human\", \"The human's name is Rahul\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f44ebefc-ba31-4901-acf4-893ffe624fb5",
      "metadata": {
        "height": 30,
        "id": "f44ebefc-ba31-4901-acf4-893ffe624fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "461d2be4-199f-43a5-f761-b439b7ed4dbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'human': \"\\nThe human's name is Rahul\", 'agent': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "agent_memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cf4d7b41-e563-4785-867a-02bd6127ceea",
      "metadata": {
        "height": 642,
        "id": "cf4d7b41-e563-4785-867a-02bd6127ceea"
      },
      "outputs": [],
      "source": [
        "# tool description\n",
        "core_memory_save_description = \"Save important information about you,\" \\\n",
        "+ \"the agent or the human you are chatting with.\"\n",
        "\n",
        "# arguments into the tool (generated by the LLM)\n",
        "# defines what the agent must generate to input into the tool\n",
        "core_memory_save_properties = \\\n",
        "{\n",
        "    # arg 1: section of memory to edit\n",
        "    \"section\": {\n",
        "        \"type\": \"string\",\n",
        "        \"enum\": [\"human\", \"agent\"],\n",
        "        \"description\": \"Must be either 'human' \" \\\n",
        "        + \"(to save information about the human) or 'agent'\" \\\n",
        "        + \"(to save information about yourself)\",\n",
        "    },\n",
        "    # arg 2: memory to save\n",
        "    \"memory\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"Memory to save in the section\",\n",
        "    },\n",
        "}\n",
        "\n",
        "# tool schema (passed to OpenAI)\n",
        "core_memory_save_metadata = \\\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"core_memory_save\",\n",
        "            \"description\": core_memory_save_description,\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": core_memory_save_properties,\n",
        "                \"required\": [\"section\", \"memory\"],\n",
        "            },\n",
        "        }\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2534c3f7-55d9-4f5f-892c-82221ccd1b78",
      "metadata": {
        "height": 353,
        "id": "2534c3f7-55d9-4f5f-892c-82221ccd1b78",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9883d419-bff7-4888-8afd-392a56fcfde1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_XQeFfk2MOgqhMp28zzhnDtzG', function=Function(arguments='{\"section\":\"human\",\"memory\":\"The human\\'s name is Virat.\"}', name='core_memory_save'), type='function')]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "agent_memory = {\"human\": \"\"}\n",
        "system_prompt = \"You are a helpful chatbot. \" \\\n",
        "+ \"You have a section of your context called [MEMORY] \" \\\n",
        "+ \"that contains information relevant to your conversation\"\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "        # system prompt\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        # memory\n",
        "        {\"role\": \"system\", \"content\": \"[MEMORY]\\n\" + json.dumps(agent_memory)},\n",
        "        # chat history\n",
        "        {\"role\": \"user\", \"content\": \"My name is Virat\"},\n",
        "    ],\n",
        "    # tool schemas\n",
        "    tools=[core_memory_save_metadata]\n",
        ")\n",
        "response = chat_completion.choices[0]\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a19d6d53-a451-48bd-b3ba-68b98c7ad7a6",
      "metadata": {
        "id": "a19d6d53-a451-48bd-b3ba-68b98c7ad7a6"
      },
      "source": [
        "### Executing the tool\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7cc0a070-d3e5-4832-90af-99d3544862e2",
      "metadata": {
        "height": 47,
        "id": "7cc0a070-d3e5-4832-90af-99d3544862e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec152fd8-0b4e-42fc-916c-26e0636bf095"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'section': 'human', 'memory': \"The human's name is Virat.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "arguments = json.loads(response.message.tool_calls[0].function.arguments)\n",
        "arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "bdcc39c5-311d-446e-9562-fa88eb2a10d1",
      "metadata": {
        "height": 47,
        "id": "bdcc39c5-311d-446e-9562-fa88eb2a10d1"
      },
      "outputs": [],
      "source": [
        "# run the function with the specified arguments\n",
        "core_memory_save(**arguments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f3219788-1cdc-4a85-af9f-b08005fabd28",
      "metadata": {
        "height": 30,
        "id": "f3219788-1cdc-4a85-af9f-b08005fabd28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f6b545-16ab-4832-bfb5-f460a55dbd37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'human': \"\\nThe human's name is Virat.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "agent_memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7996c9a1-7ed1-4c45-8f29-41dcbc0ee3f9",
      "metadata": {
        "id": "7996c9a1-7ed1-4c45-8f29-41dcbc0ee3f9"
      },
      "source": [
        "### Running the next agent step\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "93f066b8-77dc-4fcf-8c2c-f280338d8e75",
      "metadata": {
        "height": 251,
        "id": "93f066b8-77dc-4fcf-8c2c-f280338d8e75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07d3012a-bcc0-4c79-efd0-67914386bd91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletionMessage(content='Your name is Virat.', refusal=None, role='assistant', function_call=None, tool_calls=None)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "        # system prompt\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        # memory\n",
        "        {\"role\": \"system\", \"content\": \"[MEMORY]\\n\" + json.dumps(agent_memory)},\n",
        "        # chat history\n",
        "        {\"role\": \"user\", \"content\": \"what is my name\"},\n",
        "    ],\n",
        "    tools=[core_memory_save_metadata]\n",
        ")\n",
        "response = chat_completion.choices[0]\n",
        "response.message"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "357e5cab-a6ee-4539-b089-c693c58a898e",
      "metadata": {
        "id": "357e5cab-a6ee-4539-b089-c693c58a898e"
      },
      "source": [
        "## Implementing an agentic loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "673cabb2-83bb-4e7d-baed-eed6c6c67e7a",
      "metadata": {
        "height": 115,
        "id": "673cabb2-83bb-4e7d-baed-eed6c6c67e7a"
      },
      "outputs": [],
      "source": [
        "system_prompt_os = system_prompt \\\n",
        "+ \"\\n. You must either call a tool (core_memory_save) or\" \\\n",
        "+ \"write a response to the user. \" \\\n",
        "+ \"Do not take the same actions multiple times!\" \\\n",
        "+ \"When you learn new information, make sure to always\" \\\n",
        "+ \"call the core_memory_save tool.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e9d7ebbe-12f3-4949-bc89-0dc1e3b85c42",
      "metadata": {
        "height": 880,
        "id": "e9d7ebbe-12f3-4949-bc89-0dc1e3b85c42"
      },
      "outputs": [],
      "source": [
        "def agent_step(user_message):\n",
        "\n",
        "    # prefix messages with system prompt and memory\n",
        "    messages = [\n",
        "        # system prompt\n",
        "        {\"role\": \"system\", \"content\": system_prompt_os},\n",
        "        # memory\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"[MEMORY]\\n\" + json.dumps(agent_memory)\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    # append the most recent message\n",
        "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "    # agentic loop\n",
        "    while True:\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            tools=[core_memory_save_metadata]\n",
        "        )\n",
        "        response = chat_completion.choices[0]\n",
        "\n",
        "        # update the messages with the agent's response\n",
        "        messages.append(response.message)\n",
        "\n",
        "        # if NOT calling a tool (responding to the user), return\n",
        "        if not response.message.tool_calls:\n",
        "            return response.message.content\n",
        "\n",
        "        # if calling a tool, execute the tool\n",
        "        else:\n",
        "            print(\"TOOL CALL:\", response.message.tool_calls[0].function)\n",
        "\n",
        "            # parse the arguments from the LLM function call\n",
        "            arguments = json.loads(\n",
        "                response.message.tool_calls[0].function.arguments\n",
        "            )\n",
        "\n",
        "            # run the function with the specified arguments\n",
        "            core_memory_save(**arguments)\n",
        "\n",
        "            # add the tool call response to the message history\n",
        "            messages.append({\n",
        "                \"role\": \"tool\",\n",
        "                \"tool_call_id\": response.message.tool_calls[0].id,\n",
        "                \"name\": \"core_memory_save\",\n",
        "                \"content\": f\"Updated memory: {json.dumps(agent_memory)}\"\n",
        "            })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6d726ff1-e24e-4632-bf61-f55770d00466",
      "metadata": {
        "height": 30,
        "id": "6d726ff1-e24e-4632-bf61-f55770d00466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "01badef5-7de9-4fe2-c483-907b9c9d52c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOOL CALL: Function(arguments='{\"section\":\"human\",\"memory\":\"The human\\'s name is Sourav.\"}', name='core_memory_save')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Got it, Sourav! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "agent_step(\"my name is Sourav.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28bd187b-410c-4f31-b01a-2e8b0b57f43b",
      "metadata": {
        "height": 30,
        "id": "28bd187b-410c-4f31-b01a-2e8b0b57f43b"
      },
      "outputs": [],
      "source": [
        "# Try some prompts of your own!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8abd0bb7-adf3-4309-9b42-43a4d291f857",
      "metadata": {
        "height": 30,
        "id": "8abd0bb7-adf3-4309-9b42-43a4d291f857"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}